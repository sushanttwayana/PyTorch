{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T04:02:11.259617Z","iopub.execute_input":"2024-08-05T04:02:11.260072Z","iopub.status.idle":"2024-08-05T04:02:15.305313Z","shell.execute_reply.started":"2024-08-05T04:02:11.260036Z","shell.execute_reply":"2024-08-05T04:02:15.304173Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Creating a RNN model for text generation\n\nAt PyBooks, you've been tasked to develop an algorithm that can perform text generation. The project involves auto-completion of book names. To kickstart this project, you decide to experiment with a Recurrent Neural Network (RNN). This way, you can understand the nuances of RNNs before moving to more complex models.\n\nThe data variable has been initialized with an excerpt from Alice's Adventures in Wonderland by Lewis Carroll.\n\n* Include an RNN layer and linear layer in RNNmodel class\n* Instantiate the RNN model with input size as length of chars, hidden size of 16, and output size as length of chars.","metadata":{}},{"cell_type":"code","source":"# Excerpt from Alice's Adventures in Wonderland\ndata = \"Alice was beginning to get very tired having nothing to do.\"\nchars = list(set(data))\n\nchar_to_ix = {char:i for i, char in enumerate(chars)}\nix_to_char = {i:char for i, char in enumerate(chars)}","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:16:29.201535Z","iopub.execute_input":"2024-08-05T04:16:29.201925Z","iopub.status.idle":"2024-08-05T04:16:29.208083Z","shell.execute_reply.started":"2024-08-05T04:16:29.201893Z","shell.execute_reply":"2024-08-05T04:16:29.206810Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Include an RNN layer and linear layer in RNNmodel class\nclass RNNmodel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNNmodel, self).__init__()\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n        out, _ = self.rnn(x, h0)  \n        out = self.fc(out[:, -1, :])  \n        return out\n\n# Instantiate the RNN model\nmodel = RNNmodel(len(chars), 16, len(chars))\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:16:31.848571Z","iopub.execute_input":"2024-08-05T04:16:31.848976Z","iopub.status.idle":"2024-08-05T04:16:31.859613Z","shell.execute_reply.started":"2024-08-05T04:16:31.848941Z","shell.execute_reply":"2024-08-05T04:16:31.858311Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"RNNmodel(\n  (rnn): RNN(20, 16, batch_first=True)\n  (fc): Linear(in_features=16, out_features=20, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"By successfully creating this RNN model, you have taken the first step towards developing an advanced text generation system. By adding the fully connected layer for text generation, you have allowed RNN to predict the next element in a sequence. Let's further train and evaluate the model. Keep going!","metadata":{}},{"cell_type":"markdown","source":"# Preparing Inputs and target data","metadata":{}},{"cell_type":"code","source":"inputs = [char_to_ix[ch] for ch in data[:-1]]\ntargets = [char_to_ix[ch] for ch in data[1:]]\n\ninputs = torch.tensor(inputs, dtype = torch.long).view(-1,1)\n\ninputs = nn.functional.one_hot(inputs, num_classes=len(chars)).float()\n\ntargets = torch.tensor(targets, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:16:35.396101Z","iopub.execute_input":"2024-08-05T04:16:35.396503Z","iopub.status.idle":"2024-08-05T04:16:35.404660Z","shell.execute_reply.started":"2024-08-05T04:16:35.396470Z","shell.execute_reply":"2024-08-05T04:16:35.403331Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Text generation using RNN - Training and Generation\n\nThe team at PyBooks now wants you to train and test the RNN model, which is designed to predict the next character in the sequence based on the provided input for auto-completion of book names. This project will help the team further develop models for text completion.\n\n* Instantiate the loss function which will be used to compute the error of our model.\n* Instantiate the optimizer from PyTorch's optimization module.\n* Run the model training process by setting the model to the train mode and zeroing the gradients before performing an optimization step.\n* After the training process, switch the model to evaluation mode to test it on a sample input.","metadata":{}},{"cell_type":"code","source":"# Instantiate the loss function\ncriterion = nn.CrossEntropyLoss()\n# Instantiate the optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n# Train the model\nfor epoch in range(10000):\n    model.train()\n    outputs = model(inputs)\n    loss = criterion(outputs, targets)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if (epoch+1) % 1000 == 0:\n        print(f'Epoch {epoch+1}/10000, Loss: {loss.item()}')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:16:37.770669Z","iopub.execute_input":"2024-08-05T04:16:37.771106Z","iopub.status.idle":"2024-08-05T04:16:46.340580Z","shell.execute_reply.started":"2024-08-05T04:16:37.771072Z","shell.execute_reply":"2024-08-05T04:16:46.339470Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1000/10000, Loss: 2.5971486568450928\nEpoch 2000/10000, Loss: 2.415712356567383\nEpoch 3000/10000, Loss: 2.1809563636779785\nEpoch 4000/10000, Loss: 1.9657992124557495\nEpoch 5000/10000, Loss: 1.7834405899047852\nEpoch 6000/10000, Loss: 1.6260768175125122\nEpoch 7000/10000, Loss: 1.4973680973052979\nEpoch 8000/10000, Loss: 1.3980722427368164\nEpoch 9000/10000, Loss: 1.3241276741027832\nEpoch 10000/10000, Loss: 1.2701470851898193\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the model\nmodel.eval()\ntest_input = char_to_ix['b']\ntest_input = nn.functional.one_hot(torch.tensor(test_input).view(-1, 1), num_classes=len(chars)).float()\npredicted_output = model(test_input)\npredicted_char_ix = torch.argmax(predicted_output, 1).item()\nprint(f\"Test Input: 'b', Predicted Output: '{ix_to_char[predicted_char_ix]}'\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T04:17:29.636538Z","iopub.execute_input":"2024-08-05T04:17:29.637031Z","iopub.status.idle":"2024-08-05T04:17:29.645291Z","shell.execute_reply.started":"2024-08-05T04:17:29.636995Z","shell.execute_reply":"2024-08-05T04:17:29.644065Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Test Input: 'b', Predicted Output: 'e'\n","output_type":"stream"}]}]}