{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# One-hot encoded book titles\n\nPyBooks wants to catalog and analyze the book genres in its library. Apply one-hot encoding to a list of book genres to make them machine-readable.\n\n* Define the size of the vocabulary and save to vocab_size.\n* Create one-hot vectors using the appropriate torch technique and vocab_size.\n* Create a dictionary mapping genres to their corresponding one-hot vectors using dictionary comprehension; the dictionary keys should be the genre.","metadata":{}},{"cell_type":"code","source":"import torch\n\ngenres = ['Fiction','Non-fiction','Biography', 'Children','Mystery']\n\n# Define the size of the vocabulary\nvocab_size = len(genres)\n\n# Create one-hot vectors\none_hot_vectors = torch.eye(vocab_size)\n\n# Create a dictionary mapping genres to their one-hot vectors\none_hot_dict = {genre : one_hot_vectors[i] for i, genre in enumerate(genres)}\n\nfor genre, vector in one_hot_dict.items():\n    print(f'{genre}: {vector.numpy()}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-13T13:58:09.629954Z","iopub.execute_input":"2024-07-13T13:58:09.630440Z","iopub.status.idle":"2024-07-13T13:58:13.107536Z","shell.execute_reply.started":"2024-07-13T13:58:09.630399Z","shell.execute_reply":"2024-07-13T13:58:13.106021Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Fiction: [1. 0. 0. 0. 0.]\nNon-fiction: [0. 1. 0. 0. 0.]\nBiography: [0. 0. 1. 0. 0.]\nChildren: [0. 0. 0. 1. 0.]\nMystery: [0. 0. 0. 0. 1.]\n","output_type":"stream"}]},{"cell_type":"markdown","source":" The output matrix represents the presence of genres in a binary format. This type of encoding allows machines to better understand and use the genre data for various tasks, such as predicting book popularity or making book recommendations.","metadata":{}},{"cell_type":"markdown","source":"**Bag-of-words for book titles**\n\nPyBooks now has a list of book titles that need to be encoded for further analysis. The data team believes the Bag of Words (BoW) model could be the best approach.\n\n* Import the CountVectorizer class for implementing bag-of-words.\n* Initialize an object of the class you imported, then use this object to transform the titles into a matrix representation.\n* Extract and display the first five feature names and encoded titles with the get_feature_names_out() method.","metadata":{}},{"cell_type":"code","source":"import torchtext\n\n# Import from sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ntitles = ['The Great Gatsby','To Kill a Mockingbird','1984','The Catcher in the Rye',\n          'The Hobbit', 'Great Expectations']\n\n# Initialize Bag-of-words with the list of book titles\nvectorizer = CountVectorizer()\n# The fit_transform method is used to learn the vocabulary and convert the input text data into a BoW representation\nbow_encoded_titles = vectorizer.fit_transform(titles)\n\n# Extract and print the first five features\nprint(bow_encoded_titles.toarray()[0, :5])\n\n# The get_feature_names_out method returns the list of feature names (unique words in the vocabulary)\nprint(vectorizer.get_feature_names_out()[:5])","metadata":{"execution":{"iopub.status.busy":"2024-07-13T13:58:16.257572Z","iopub.execute_input":"2024-07-13T13:58:16.258140Z","iopub.status.idle":"2024-07-13T13:58:19.506417Z","shell.execute_reply.started":"2024-07-13T13:58:16.258104Z","shell.execute_reply":"2024-07-13T13:58:19.505265Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[0 0 0 1 1]\n['1984' 'catcher' 'expectations' 'gatsby' 'great']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The BoW representation is a sparse matrix where each row represents a document (title) and each column represents a unique word in the vocabulary. The value at position (i, j) in the matrix indicates the count of the j-th word in the i-th document.\n\nThe output matrix provides a clear picture of the word frequencies in the book titles. By analyzing the output, you can identify the frequency of words like 'catcher' and 'great' in the titles. The word frequency feature vectors can be used later by machine learning algorithms.","metadata":{}},{"cell_type":"code","source":"# Extract and print the first five features\nprint(bow_encoded_titles.toarray())\nprint(vectorizer.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2024-07-13T13:58:24.507384Z","iopub.execute_input":"2024-07-13T13:58:24.508877Z","iopub.status.idle":"2024-07-13T13:58:24.515721Z","shell.execute_reply.started":"2024-07-13T13:58:24.508835Z","shell.execute_reply":"2024-07-13T13:58:24.514439Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[[0 0 0 1 1 0 0 0 0 0 1 0]\n [0 0 0 0 0 0 0 1 1 0 0 1]\n [1 0 0 0 0 0 0 0 0 0 0 0]\n [0 1 0 0 0 0 1 0 0 1 2 0]\n [0 0 0 0 0 1 0 0 0 0 1 0]\n [0 0 1 0 1 0 0 0 0 0 0 0]]\n['1984' 'catcher' 'expectations' 'gatsby' 'great' 'hobbit' 'in' 'kill'\n 'mockingbird' 'rye' 'the' 'to']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* The vocabulary is ['1984', 'catcher', 'expectations', 'gatsby', 'great', 'hobbit', 'in', 'kill', 'mockingbird', 'rye', 'the', 'to'].\n\n* The BoW vector for \"The Great Gatsby\" is [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0].\n\n* The value at index 3 (gatsby) is 1 because \"gatsby\" appears once in the title.\n* The value at index 4 (great) is 1 because \"great\" appears once in the title.\n* The value at index 10 (the) is 1 because \"the\" appears once in the title.\n* All other values are 0 because the corresponding words do not appear in the title.","metadata":{}},{"cell_type":"markdown","source":"**Applying TF-IDF to book descriptions**\n\nPyBooks has collected several book descriptions and wants to identify important words within them using the TF-IDF encoding technique. By doing this, they hope to gain more insights into the unique attributes of each book to help with their book recommendation system.\n\n* Import the class from sklearn.feature_extraction.text that converts a collection of raw documents to a matrix of TF-IDF features.\n* Instantiate an object of this class, then use this object to encode the descriptions into a TF-IDF matrix of vectors.\n* Retrieve and display the first five feature names from the vectorizer and encoded vectors from tfidf_encoded_descriptions.","metadata":{}},{"cell_type":"code","source":"# Importing TF-IDF from sklearn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ndescriptions = [\n    \"This is the first document.\",\n    \"This document is the second document.\",\n    \"And this is the third one.\",\n    \"Is this the first document?\"\n]\n\n# Initialize TF-IDF encoding vectorizer\nvectorizer = TfidfVectorizer()\ntfidf_encoded_descriptions = vectorizer.fit_transform(descriptions)\n\n# Extract and print the first five features\nprint(tfidf_encoded_descriptions.toarray()[0, :5])\nprint(vectorizer.get_feature_names_out()[:5])","metadata":{"execution":{"iopub.status.busy":"2024-07-13T14:01:07.198083Z","iopub.execute_input":"2024-07-13T14:01:07.199291Z","iopub.status.idle":"2024-07-13T14:01:07.218200Z","shell.execute_reply.started":"2024-07-13T14:01:07.199238Z","shell.execute_reply":"2024-07-13T14:01:07.216849Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[0.         0.46979139 0.58028582 0.38408524 0.        ]\n['and' 'document' 'first' 'is' 'one']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract and print the first five features\nprint(tfidf_encoded_descriptions.toarray())\nprint(vectorizer.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2024-07-13T14:01:23.957474Z","iopub.execute_input":"2024-07-13T14:01:23.957896Z","iopub.status.idle":"2024-07-13T14:01:23.965831Z","shell.execute_reply.started":"2024-07-13T14:01:23.957863Z","shell.execute_reply":"2024-07-13T14:01:23.964432Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n  0.38408524 0.         0.38408524]\n [0.         0.6876236  0.         0.28108867 0.         0.53864762\n  0.28108867 0.         0.28108867]\n [0.51184851 0.         0.         0.26710379 0.51184851 0.\n  0.26710379 0.51184851 0.26710379]\n [0.         0.46979139 0.58028582 0.38408524 0.         0.\n  0.38408524 0.         0.38408524]]\n['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"By examining the feature names and their corresponding TF-IDF values, you can uncover significant words that contribute to the uniqueness and relevance of each book. Your team is excited about the insights gained from your analysis. Keep up the great work!","metadata":{}}]}