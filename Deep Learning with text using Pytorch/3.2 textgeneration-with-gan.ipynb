{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T07:26:31.356682Z","iopub.execute_input":"2024-08-05T07:26:31.357716Z","iopub.status.idle":"2024-08-05T07:26:34.998218Z","shell.execute_reply.started":"2024-08-05T07:26:31.357675Z","shell.execute_reply":"2024-08-05T07:26:34.997130Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Building a generator and discriminator\n\nAt PyBooks, you're tasked with working on an automatic text generator to help writers overcome writer's block. By using GANs, or Generative Adversarial Networks, you believe you can create a system where one network, the generator, creates new text while the other network, the discriminator, evaluates its authenticity. To do this, you need to initialize both a generator and discriminator network. These networks will then be trained against each other to create new, believable text.\n\n* Define the Generator class with a linear layer for sequential data and a sigmoid activation function.\n* Pass the input through the defined model in the forward() method of the Generator class.\n* Define a Discriminator class with the same layers and activation function, taking care when defining the dimensions.","metadata":{}},{"cell_type":"code","source":"# Define the generator class\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(nn.Linear(seq_length, seq_length), nn.Sigmoid())\n    def forward(self, x):\n        return self.model(x)\n\n# Define the discriminator networks\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(nn.Linear(seq_length, 1), nn.Sigmoid())\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T07:29:27.095018Z","iopub.execute_input":"2024-08-05T07:29:27.095456Z","iopub.status.idle":"2024-08-05T07:29:27.104131Z","shell.execute_reply.started":"2024-08-05T07:29:27.095421Z","shell.execute_reply":"2024-08-05T07:29:27.102631Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Great work! You have successfully defined a generator and a discriminator for your GAN. These networks will be the backbone of your text generation system. Now you're ready to move on to the next step, which is to train these networks against each other so they can start generating and evaluating new text!","metadata":{}},{"cell_type":"markdown","source":"# Training a GAN model\n\nYour team at PyBooks has made good progress in building the text generator using a Generative Adversarial Network (GAN). You have successfully defined the generator and discriminator networks. Now, it's time to train them. The final step is to generate some fake data and compare it with the real data to see how well your GAN has learned. We have used tensors as an input and the output would try to resemble the input tensors. The team at PyBooks can then use this synthetic data for text analysis as the features will have same relationship as text data.\n\n\n* Define the loss function for binary classification and the Adam optimizer.\n* Train the discriminator by unsqueezing real_data and preventing gradient recalculations.\n* Train the generator by calculating the loss and zeroing the gradients.\n* Detach the tensor to prevent further computation and print data.","metadata":{}},{"cell_type":"code","source":"seq_length = 5# Length of each synthetic data sequence\nnum_sequences = 100 # Total number of sequences generated\nnum_epochs = 100 #Number of complete passes through the dataset\nprint_every = 10 #Output display frequency, showing results every 10 epochs\n\n# Generate random synthetic data\n# data = torch.rand((num_sequences, seq_length))\ndata = torch.randint(0, 2, (num_sequences, seq_length)).float()\n\n# Initialize Generator and Discriminator\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n\n# Define the loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer_gen = torch.optim.Adam(generator.parameters(), lr=0.001)\noptimizer_disc = torch.optim.Adam(discriminator.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T07:42:19.403207Z","iopub.execute_input":"2024-08-05T07:42:19.403670Z","iopub.status.idle":"2024-08-05T07:42:19.414082Z","shell.execute_reply.started":"2024-08-05T07:42:19.403634Z","shell.execute_reply":"2024-08-05T07:42:19.412845Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Training Generator and Dicriminator**","metadata":{}},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    for real_data in data:\n        # Unsqueezing real_data and prevent gradient recalculations\n        real_data = real_data.unsqueeze(0)\n        noise = torch.rand((1, seq_length))\n        fake_data = generator(noise)\n        disc_real = discriminator(real_data)\n        disc_fake = discriminator(fake_data.detach())\n        loss_disc = criterion(disc_real, torch.ones_like(disc_real)) + criterion(disc_fake, torch.zeros_like(disc_fake))\n        optimizer_disc.zero_grad()\n        loss_disc.backward()\n        optimizer_disc.step()\n\n        # Train the generator\n        disc_fake = discriminator(fake_data)\n        loss_gen = criterion(disc_fake, torch.ones_like(disc_fake))\n        optimizer_gen.zero_grad()\n        loss_gen.backward()\n        optimizer_gen.step()\n\n    if (epoch+1) % print_every == 0:\n        print(f\"Epoch {epoch+1}/{num_epochs}:\\t Generator loss: {loss_gen.item()}\\t Discriminator loss: {loss_disc.item()}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T07:42:22.446079Z","iopub.execute_input":"2024-08-05T07:42:22.446514Z","iopub.status.idle":"2024-08-05T07:42:36.715928Z","shell.execute_reply.started":"2024-08-05T07:42:22.446480Z","shell.execute_reply":"2024-08-05T07:42:36.714626Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 10/100:\t Generator loss: 0.6969020962715149\t Discriminator loss: 1.415478229522705\nEpoch 20/100:\t Generator loss: 0.7014884352684021\t Discriminator loss: 1.4510271549224854\nEpoch 30/100:\t Generator loss: 0.6903109550476074\t Discriminator loss: 1.3721253871917725\nEpoch 40/100:\t Generator loss: 0.7007946968078613\t Discriminator loss: 1.4018926620483398\nEpoch 50/100:\t Generator loss: 0.6807171702384949\t Discriminator loss: 1.3390090465545654\nEpoch 60/100:\t Generator loss: 0.7054358720779419\t Discriminator loss: 1.365788221359253\nEpoch 70/100:\t Generator loss: 0.6885059475898743\t Discriminator loss: 1.4076051712036133\nEpoch 80/100:\t Generator loss: 0.7028335928916931\t Discriminator loss: 1.3930323123931885\nEpoch 90/100:\t Generator loss: 0.6895354986190796\t Discriminator loss: 1.4109766483306885\nEpoch 100/100:\t Generator loss: 0.6818939447402954\t Discriminator loss: 1.3375091552734375\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\nReal data: \")\nprint(data[:5])\n\n\nprint(\"\\nGenerated data: \")\nfor _ in range(5):\n    noise = torch.rand((1, seq_length))\n    generated_data = generator(noise)\n    # Detach the tensor and print data\n    print(torch.round(generated_data).detach())","metadata":{"execution":{"iopub.status.busy":"2024-08-05T07:42:42.680746Z","iopub.execute_input":"2024-08-05T07:42:42.681228Z","iopub.status.idle":"2024-08-05T07:42:42.693446Z","shell.execute_reply.started":"2024-08-05T07:42:42.681193Z","shell.execute_reply":"2024-08-05T07:42:42.692299Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\nReal data: \ntensor([[0., 1., 1., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 1., 1., 0., 0.],\n        [1., 1., 0., 0., 0.],\n        [1., 0., 0., 1., 1.]])\n\nGenerated data: \ntensor([[0., 0., 0., 0., 0.]])\ntensor([[0., 1., 0., 0., 0.]])\ntensor([[0., 0., 0., 0., 0.]])\ntensor([[0., 0., 0., 0., 0.]])\ntensor([[0., 0., 0., 0., 0.]])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}