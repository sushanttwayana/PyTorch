{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:20:01.940597Z","iopub.execute_input":"2024-08-01T16:20:01.940987Z","iopub.status.idle":"2024-08-01T16:20:01.947384Z","shell.execute_reply.started":"2024-08-01T16:20:01.940956Z","shell.execute_reply":"2024-08-01T16:20:01.945942Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ncategories = ['rec.autos', 'sci.med', 'comp.graphics']\nnewsgroups = fetch_20newsgroups(subset='all', categories=categories)\nvectorizer = CountVectorizer(max_features=5000)\nX = vectorizer.fit_transform(newsgroups.data).toarray()\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(newsgroups.target)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:20:11.576802Z","iopub.execute_input":"2024-08-01T16:20:11.577219Z","iopub.status.idle":"2024-08-01T16:20:12.749604Z","shell.execute_reply.started":"2024-08-01T16:20:11.577160Z","shell.execute_reply":"2024-08-01T16:20:12.748418Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(y[:10])","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:20:14.823636Z","iopub.execute_input":"2024-08-01T16:20:14.824048Z","iopub.status.idle":"2024-08-01T16:20:14.829940Z","shell.execute_reply.started":"2024-08-01T16:20:14.824017Z","shell.execute_reply":"2024-08-01T16:20:14.828653Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[1 0 1 1 0 0 2 0 2 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Convert data to PyTorch tensors\nX_train_seq = torch.tensor(X_train, dtype=torch.float32)\nX_test_seq = torch.tensor(X_test, dtype=torch.float32)\ny_train_seq = torch.tensor(y_train, dtype=torch.long)\ny_test_seq = torch.tensor(y_test, dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:20:16.855279Z","iopub.execute_input":"2024-08-01T16:20:16.855818Z","iopub.status.idle":"2024-08-01T16:20:16.945979Z","shell.execute_reply.started":"2024-08-01T16:20:16.855774Z","shell.execute_reply":"2024-08-01T16:20:16.944726Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Parameters\ninput_size = X_train_seq.shape[1]\nhidden_size = 32\nnum_layers = 2\nnum_classes = 3","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:22:51.069190Z","iopub.execute_input":"2024-08-01T16:22:51.069694Z","iopub.status.idle":"2024-08-01T16:22:51.075477Z","shell.execute_reply.started":"2024-08-01T16:22:51.069660Z","shell.execute_reply":"2024-08-01T16:22:51.073908Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Building an RNN model for text\n\nAs a data analyst at PyBooks, you often encounter datasets that contain sequential information, such as customer interactions, time series data, or text documents. RNNs can effectively analyze and extract insights from such data. In this exercise, you will dive into the Newsgroup dataset that has already been processed and encoded for you. This dataset comprises articles from different categories. Your task is to apply an RNN to classify these articles into three categories:\n\nrec.autos, sci.med, and comp.graphics.\n\nThis and the following exercises use the fetch_20newsgroups dataset from sklearn.\n\n* Complete the RNN class with an RNN layer and a fully connected linear layer.\n* Initialize the model.\n* Train the RNN model for ten epochs by zeroing the gradients.","metadata":{}},{"cell_type":"code","source":"# Complete the RNN class\nclass RNNModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(RNNModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, num_classes)        \n        \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        out, _ = self.rnn(x, h0)\n        out = out[:, -1, :] \n        out = self.fc(out)\n        return out\n\n# Initialize the model\nrnn_model = RNNModel(input_size, hidden_size, num_layers, num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(rnn_model.parameters(), lr=0.01)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:23:08.796833Z","iopub.execute_input":"2024-08-01T16:23:08.797252Z","iopub.status.idle":"2024-08-01T16:23:08.810338Z","shell.execute_reply.started":"2024-08-01T16:23:08.797217Z","shell.execute_reply":"2024-08-01T16:23:08.809151Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Train the model for ten epochs and zero the gradients\nfor epoch in range(50):\n    optimizer.zero_grad()\n    outputs = rnn_model(X_train_seq.unsqueeze(1))  # Add a dimension for batch_first\n    loss = criterion(outputs, y_train_seq)\n    loss.backward()\n    optimizer.step()\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:20:23.788888Z","iopub.execute_input":"2024-08-01T16:20:23.789296Z","iopub.status.idle":"2024-08-01T16:20:24.930913Z","shell.execute_reply.started":"2024-08-01T16:20:23.789262Z","shell.execute_reply":"2024-08-01T16:20:24.929514Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch: 1, Loss: 1.118180274963379\nEpoch: 2, Loss: 0.9855406880378723\nEpoch: 3, Loss: 0.8225328922271729\nEpoch: 4, Loss: 0.6509308815002441\nEpoch: 5, Loss: 0.48327064514160156\nEpoch: 6, Loss: 0.3461679220199585\nEpoch: 7, Loss: 0.24381475150585175\nEpoch: 8, Loss: 0.1678209751844406\nEpoch: 9, Loss: 0.11352389305830002\nEpoch: 10, Loss: 0.07626967132091522\nEpoch: 11, Loss: 0.051638681441545486\nEpoch: 12, Loss: 0.03534931689500809\nEpoch: 13, Loss: 0.024788090959191322\nEpoch: 14, Loss: 0.01802026852965355\nEpoch: 15, Loss: 0.013481352478265762\nEpoch: 16, Loss: 0.010755353607237339\nEpoch: 17, Loss: 0.00882408395409584\nEpoch: 18, Loss: 0.007347017992287874\nEpoch: 19, Loss: 0.006084200460463762\nEpoch: 20, Loss: 0.004938804544508457\nEpoch: 21, Loss: 0.00394572876393795\nEpoch: 22, Loss: 0.0031631074380129576\nEpoch: 23, Loss: 0.002519233152270317\nEpoch: 24, Loss: 0.0019569513387978077\nEpoch: 25, Loss: 0.0015221353387460113\nEpoch: 26, Loss: 0.0012471586233004928\nEpoch: 27, Loss: 0.0010795190464705229\nEpoch: 28, Loss: 0.0009679447975941002\nEpoch: 29, Loss: 0.0008898352971300483\nEpoch: 30, Loss: 0.0008298209868371487\nEpoch: 31, Loss: 0.0007796414429321885\nEpoch: 32, Loss: 0.0007342160097323358\nEpoch: 33, Loss: 0.0006907886709086597\nEpoch: 34, Loss: 0.0006488349172286689\nEpoch: 35, Loss: 0.0006092271651141346\nEpoch: 36, Loss: 0.0005730481934733689\nEpoch: 37, Loss: 0.0005408745491877198\nEpoch: 38, Loss: 0.000512686325237155\nEpoch: 39, Loss: 0.00048811378655955195\nEpoch: 40, Loss: 0.0004666669119615108\nEpoch: 41, Loss: 0.00044786607031710446\nEpoch: 42, Loss: 0.00043129007099196315\nEpoch: 43, Loss: 0.0004165927821304649\nEpoch: 44, Loss: 0.00040348514448851347\nEpoch: 45, Loss: 0.0003917342110071331\nEpoch: 46, Loss: 0.0003811410570051521\nEpoch: 47, Loss: 0.00037155114114284515\nEpoch: 48, Loss: 0.0003628259291872382\nEpoch: 49, Loss: 0.0003548559616319835\nEpoch: 50, Loss: 0.0003475403063930571\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Model loss should always decrease as it shows how well the model has learned new patterns. Keep up the excellent work!","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\nrnn_model.eval()\nwith torch.no_grad():\n    outputs = rnn_model(X_test_seq)\n    _, predicted = torch.max(outputs, 1)\n    accuracy = accuracy_score(y_test_seq, predicted)\n    print(f'Test Accuracy: {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:32:47.882848Z","iopub.execute_input":"2024-08-01T16:32:47.883250Z","iopub.status.idle":"2024-08-01T16:32:48.015040Z","shell.execute_reply.started":"2024-08-01T16:32:47.883218Z","shell.execute_reply":"2024-08-01T16:32:48.013452Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":38,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m rnn_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test_seq, predicted)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[28], line 12\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m---> 12\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \n\u001b[1;32m     14\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:529\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 529\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    530\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    531\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"],"ename":"RuntimeError","evalue":"For unbatched 2-D input, hx should also be 2-D but got 3-D tensor","output_type":"error"}]},{"cell_type":"markdown","source":"# Building an LSTM model for text\n\nAt PyBooks, the team is constantly seeking to enhance the user experience by leveraging the latest advancements in technology. In line with this vision, they have assigned you a critical task. The team wants you to explore the potential of another powerful tool: LSTM, known for capturing more complexities in data patterns. You are working with the same Newsgroup dataset, with the objective remaining unchanged: to classify news articles into three distinct categories:\n\nrec.autos, sci.med, and comp.graphics.\n\n* Set up an LSTM model by completing the LSTM and linear layers with the necessary parameters.\n* Initialize the model with the necessary parameters.\n* Train the LSTM model resetting the gradients to zero and passing the input data X_train_seq through the model.\n* Calculate the loss based on the predicted outputs and the true labels.\n\n\n","metadata":{}},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(LSTMModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, num_classes)        \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        out, _ = self.lstm(x.unsqueeze(1), (h0, c0))  # Reshape input to (batch_size, seq_length, input_size)\n        out = out[:, -1, :] \n        out = self.fc(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:24:04.312424Z","iopub.execute_input":"2024-08-01T16:24:04.312834Z","iopub.status.idle":"2024-08-01T16:24:04.321085Z","shell.execute_reply.started":"2024-08-01T16:24:04.312802Z","shell.execute_reply":"2024-08-01T16:24:04.319802Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Initialize model with required parameters\nlstm_model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(lstm_model.parameters(), lr=0.01)\n\n# Train the model by passing the correct parameters and zeroing the gradient\nfor epoch in range(10): \n    optimizer.zero_grad()\n    outputs = lstm_model(X_train_seq)\n    loss = criterion(outputs, y_train_seq)\n    loss.backward()\n    optimizer.step()\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:24:06.727110Z","iopub.execute_input":"2024-08-01T16:24:06.728089Z","iopub.status.idle":"2024-08-01T16:24:08.330700Z","shell.execute_reply.started":"2024-08-01T16:24:06.728053Z","shell.execute_reply":"2024-08-01T16:24:08.329593Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch: 1, Loss: 1.1001509428024292\nEpoch: 2, Loss: 1.072670817375183\nEpoch: 3, Loss: 1.0309168100357056\nEpoch: 4, Loss: 0.9662202000617981\nEpoch: 5, Loss: 0.8806395530700684\nEpoch: 6, Loss: 0.7788384556770325\nEpoch: 7, Loss: 0.6678829789161682\nEpoch: 8, Loss: 0.5554749965667725\nEpoch: 9, Loss: 0.4473586976528168\nEpoch: 10, Loss: 0.3498893678188324\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\nlstm_model.eval()\nwith torch.no_grad():\n    outputs = lstm_model(X_test_seq)\n    _, predicted = torch.max(outputs, 1)\n    accuracy = accuracy_score(y_test_seq, predicted)\n    print(f'Test Accuracy: {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:24:24.249885Z","iopub.execute_input":"2024-08-01T16:24:24.250269Z","iopub.status.idle":"2024-08-01T16:24:24.299165Z","shell.execute_reply.started":"2024-08-01T16:24:24.250237Z","shell.execute_reply":"2024-08-01T16:24:24.298078Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.95\n","output_type":"stream"}]},{"cell_type":"markdown","source":" The output presents model loss that would keep decreasing with each epoch. This information could be utilized by the team at PyBooks to compare with other models. Keep up the great w","metadata":{}},{"cell_type":"markdown","source":"# Building a GRU model for text\n\nAt PyBooks, the team has been impressed with the performance of the two models you previously trained. However, in their pursuit of excellence, they want to ensure the selection of the absolute best model for the task at hand. Therefore, they have asked you to further expand the project by experimenting with the capabilities of GRU models, renowned for their efficiency and effectiveness in text classification tasks. Your new assignment is to apply the GRU model to classify articles from the Newsgroup dataset into the following categories:\n\nrec.autos, sci.med, and comp.graphics.\n\n* Complete the GRU class with the required parameters.\n* Initialize the model with the same parameters.\n* Train the model: pass the parameters to the criterion function, and backpropagate the loss.","metadata":{}},{"cell_type":"code","source":"# Complete the GRU model\nclass GRUModel(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(GRUModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, num_classes)\n        \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n        out, _ = self.gru(x.unsqueeze(1), h0)  # Reshape input to (batch_size, seq_length, input_size)\n        out = out[:, -1, :]\n        out = self.fc(out)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:31:53.235555Z","iopub.execute_input":"2024-08-01T16:31:53.235995Z","iopub.status.idle":"2024-08-01T16:31:53.244059Z","shell.execute_reply.started":"2024-08-01T16:31:53.235962Z","shell.execute_reply":"2024-08-01T16:31:53.242859Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\ngru_model = GRUModel(input_size, hidden_size, num_layers, num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(gru_model.parameters(), lr=0.01)\n\n# Train the model and backpropagate the loss after initialization\nfor epoch in range(15):\n    optimizer.zero_grad()\n    outputs = gru_model(X_train_seq)\n    loss = criterion(outputs, y_train_seq)\n    loss.backward()\n    optimizer.step()\n    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:31:56.640044Z","iopub.execute_input":"2024-08-01T16:31:56.640931Z","iopub.status.idle":"2024-08-01T16:31:57.421266Z","shell.execute_reply.started":"2024-08-01T16:31:56.640890Z","shell.execute_reply":"2024-08-01T16:31:57.420152Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch: 1, Loss: 1.1020915508270264\nEpoch: 2, Loss: 1.0381512641906738\nEpoch: 3, Loss: 0.9452874064445496\nEpoch: 4, Loss: 0.8157745003700256\nEpoch: 5, Loss: 0.6671879291534424\nEpoch: 6, Loss: 0.5211980938911438\nEpoch: 7, Loss: 0.3891841173171997\nEpoch: 8, Loss: 0.27994370460510254\nEpoch: 9, Loss: 0.19415798783302307\nEpoch: 10, Loss: 0.13082453608512878\nEpoch: 11, Loss: 0.08623056858778\nEpoch: 12, Loss: 0.056182049214839935\nEpoch: 13, Loss: 0.036781881004571915\nEpoch: 14, Loss: 0.024478556588292122\nEpoch: 15, Loss: 0.016716597601771355\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluate the model\ngru_model.eval()\nwith torch.no_grad():\n    outputs = gru_model(X_test_seq)\n    _, predicted = torch.max(outputs, 1)\n    accuracy = accuracy_score(y_test_seq, predicted)\n    print(f'Test Accuracy: {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-01T16:32:17.510905Z","iopub.execute_input":"2024-08-01T16:32:17.511310Z","iopub.status.idle":"2024-08-01T16:32:17.530712Z","shell.execute_reply.started":"2024-08-01T16:32:17.511276Z","shell.execute_reply":"2024-08-01T16:32:17.529431Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Test Accuracy: 0.96\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You've effectively trained GRU models for text classification. The decreasing model loss across epochs is promising, and can be used by the PyBooks team for comparison with other models!\n","metadata":{}},{"cell_type":"markdown","source":"# For testing","metadata":{}}]}