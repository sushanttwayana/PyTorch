{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-06T08:29:01.215220Z","iopub.execute_input":"2024-08-06T08:29:01.216072Z","iopub.status.idle":"2024-08-06T08:29:04.441343Z","shell.execute_reply.started":"2024-08-06T08:29:01.216026Z","shell.execute_reply":"2024-08-06T08:29:04.439981Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Creating a transformer model\n\nAt PyBooks, the recommendation engine you're working on needs more refined capabilities to understand the sentiments of user reviews. You believe that using transformers, a state-of-the-art architecture, can help achieve this. You decide to build a transformer model that can encode the sentiments in the reviews to kickstart the project.\n\nThe input data contains sentences such as : \"I love this product\", \"This is terrible\", \"Could be better\" â€¦ and their respective binary sentiment labels such as : 1, 0, 0, ...\n\nThe input data is split and converted to embeddings in the following variables: train_sentences, train_labels ,test_sentences,test_labels,token_embeddings\n\n* Initialize the transformer encoder.\n* Define the fully connected layer based on the number of sentiment classes.\n* In the forward method, pass the input through the transformer encoder followed by the linear layer.","metadata":{}},{"cell_type":"code","source":"sentences = [\"I love this product\", \"This is terrible\", \"Could be better\", \"This is the best\",\n             \"Absolutely fantastic\", \"Not worth the money\", \"I am very satisfied\", \"Disappointed\",\n             \"Exceeded my expectations\", \"Will not buy again\", \"Highly recommended\", \"Terrible experience\",\n             \"Pretty good\", \"Not as described\", \"Works as expected\", \"Very bad\", \"Best purchase ever\",\n             \"Not happy\", \"Awesome\", \"Regret buying this\", \"Satisfactory\", \"Amazing quality\", \"Bad quality\",\n             \"Very useful\", \"Useless\", \"Happy with my purchase\", \"Total waste of money\", \"Excellent\",\n             \"Would buy again\", \"Cheap and unreliable\", \"Great value\", \"Poor performance\", \"Love it\",\n             \"Would not recommend\", \"Decent\", \"Waste of time\", \"Superb\", \"Not worth it\", \"I am impressed\",\n             \"Very disappointing\", \"Good value for money\", \"Horrible\", \"Pleasantly surprised\", \"Awful\",\n             \"Satisfied\", \"Worst purchase\", \"Great product\", \"Not as expected\", \"Top quality\", \"Terrible service\",\n             \"Happy with it\"]\n\nlabels = [1, 0, 0, 1, \n          1, 0, 1, 0, \n          1, 0, 1, 0, \n          1, 0, 1, 0, \n          1, 0, 1, 0, \n          1, 1, 0, 1, \n          0, 1, 0, 1, \n          1, 0, 1, 0, \n          1, 0, 1, 0, \n          1, 1, 0, 1, \n          0, 1, 0, 1, \n          1, 0, 1, 0, \n          1, 0, 1, 0, \n          1, 0, 1, 0, \n          1, 1]\n\ntrain_sentences = sentences[:40]\ntrain_labels = labels[:40]\ntest_sentences = sentences[40:]\ntest_labels = labels[40:]\n\n# Example token embeddings with a size of 512\nembedding_dim = 512\ntoken_embeddings = {word: torch.randn(embedding_dim) for word in {\n    \"I\", \"love\", \"this\", \"product\", \"is\", \"terrible\", \"Could\", \"be\", \"better\", \n    \"the\", \"best\", \"Absolutely\", \"fantastic\", \"Not\", \"worth\", \"money\", \"am\", \n    \"very\", \"satisfied\", \"Disappointed\", \"Exceeded\", \"my\", \"expectations\", \n    \"Will\", \"not\", \"buy\", \"again\", \"Highly\", \"recommended\", \"experience\", \n    \"Pretty\", \"good\", \"as\", \"described\", \"Works\", \"expected\", \"bad\", \"Best\", \n    \"purchase\", \"ever\", \"happy\", \"Awesome\", \"Regret\", \"buying\", \"Satisfactory\", \n    \"Amazing\", \"quality\", \"Bad\", \"Very\", \"useful\", \"Useless\", \"Happy\", \"with\", \n    \"Total\", \"waste\", \"Excellent\", \"Would\", \"Cheap\", \"and\", \"unreliable\", \n    \"Great\", \"value\", \"Poor\", \"performance\", \"Love\", \"it\", \"recommend\", \"Decent\", \n    \"Waste\", \"time\", \"Superb\", \"worth\", \"impressed\", \"disappointing\", \"Good\", \n    \"for\", \"Horrible\", \"Pleasantly\", \"surprised\", \"Awful\", \"Satisfied\", \"Worst\", \n    \"service\", \"Top\"\n}}","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:44:16.761361Z","iopub.execute_input":"2024-08-06T08:44:16.761739Z","iopub.status.idle":"2024-08-06T08:44:16.779744Z","shell.execute_reply.started":"2024-08-06T08:44:16.761710Z","shell.execute_reply":"2024-08-06T08:44:16.778428Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Ensure all tokens in sentences are in token_embeddings\nall_tokens = set(token for sentence in sentences for token in sentence.split())\nembedding_dim = 512\n\n# Update token_embeddings to include all tokens\nfor token in all_tokens:\n    if token not in token_embeddings:\n        token_embeddings[token] = torch.randn(embedding_dim)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:45:48.017725Z","iopub.execute_input":"2024-08-06T08:45:48.018161Z","iopub.status.idle":"2024-08-06T08:45:48.025162Z","shell.execute_reply.started":"2024-08-06T08:45:48.018123Z","shell.execute_reply":"2024-08-06T08:45:48.023680Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, embed_size, heads, num_layers, dropout):\n        super(TransformerEncoder, self).__init__()\n        # Initialize the encoder \n        self.encoder = nn.TransformerEncoder(\n            nn.TransformerEncoderLayer(d_model=embed_size, nhead=heads),\n            num_layers=num_layers)\n        # Define the fully connected layer\n        self.fc = nn.Linear(embed_size, 2)\n\n    def forward(self, x):\n        # Pass the input through the transformer encoder \n        x = self.encoder(x)\n        x = x.mean(dim=1) \n        return self.fc(x)\n\nmodel = TransformerEncoder(embed_size=512, heads=8, num_layers=3, dropout=0.5)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:44:19.020355Z","iopub.execute_input":"2024-08-06T08:44:19.020777Z","iopub.status.idle":"2024-08-06T08:44:19.079271Z","shell.execute_reply.started":"2024-08-06T08:44:19.020747Z","shell.execute_reply":"2024-08-06T08:44:19.077836Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"You've successfully created a Transformer model for sentiment analysis. With this architecture, you can encode and understand the nuances of reviews more effectively. Let's move on to training this model.","metadata":{}},{"cell_type":"code","source":"train_sentences = [\"I love this product\", \"This is terrible\", \"Could be better\", \"This is the best\",\n                   \"Absolutely fantastic\", \"Not worth the money\", \"I am very satisfied\", \"Disappointed\",\n                   \"Exceeded my expectations\", \"Will not buy again\", \"Highly recommended\", \"Terrible experience\",\n                   \"Pretty good\", \"Not as described\", \"Works as expected\", \"Very bad\", \"Best purchase ever\",\n                   \"Not happy\", \"Awesome\", \"Regret buying this\", \"Satisfactory\", \"Amazing quality\", \"Bad quality\",\n                   \"Very useful\", \"Useless\", \"Happy with my purchase\", \"Total waste of money\", \"Excellent\",\n                   \"Would buy again\", \"Cheap and unreliable\", \"Great value\", \"Poor performance\", \"Love it\",\n                   \"Would not recommend\", \"Decent\", \"Waste of time\", \"Superb\", \"Not worth it\", \"I am impressed\",\n                   \"Very disappointing\", \"Good value for money\"]\ntrain_labels = [1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n                1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:44:21.196509Z","iopub.execute_input":"2024-08-06T08:44:21.196947Z","iopub.status.idle":"2024-08-06T08:44:21.207694Z","shell.execute_reply.started":"2024-08-06T08:44:21.196910Z","shell.execute_reply":"2024-08-06T08:44:21.206042Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Training and testing the Transformer \n\nWith the TransformerEncoder model in place, the next step at PyBooks is to train the model on sample reviews and evaluate its performance. Training on these sample reviews will help PyBooks understand the sentiment trends in their vast repository. By achieving a well-performing model, PyBooks can then automate sentiment analysis, ensuring readers get insightful recommendations and feedback.\n\n\nThe model instance of the TransformerEncoder class, token_embeddings, and the train_sentences, train_labels ,test_sentences,test_labels are preloaded for you.\n\n* In the training loop, split the sentences into tokens and stack the embeddings.\n* Zero the gradients and perform a backward pass.\n* In the predict function, deactivate the gradient computations then get the sentiment prediction.","metadata":{}},{"cell_type":"code","source":"# Training loop\nfor epoch in range(5):\n    for sentence, label in zip(train_sentences, train_labels):\n        tokens = sentence.split()\n        data = torch.stack([token_embeddings[token] for token in tokens], dim=0).unsqueeze(0)\n        output = model(data)\n        loss = criterion(output, torch.tensor([label]))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n     \n    print(f\"Epoch {epoch} , Loss: {loss.item()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:46:46.872719Z","iopub.execute_input":"2024-08-06T08:46:46.873136Z","iopub.status.idle":"2024-08-06T08:46:59.358825Z","shell.execute_reply.started":"2024-08-06T08:46:46.873101Z","shell.execute_reply":"2024-08-06T08:46:59.357361Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 0 , Loss: 0.5028645396232605\nEpoch 1 , Loss: 0.7015641927719116\nEpoch 2 , Loss: 0.8257874250411987\nEpoch 3 , Loss: 1.4521418809890747\nEpoch 4 , Loss: 1.272108793258667\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define accuracy calculation function\ndef calculate_accuracy(predictions, labels):\n    preds = torch.argmax(predictions, dim=1)\n    correct = (preds == labels).float()\n    return correct.sum() / len(correct)\n\n# Training loop\nfor epoch in range(10):  # Increase the number of epochs\n    model.train()\n    epoch_loss = 0\n    epoch_acc = 0\n    for sentence, label in zip(train_sentences, train_labels):\n        tokens = sentence.split()\n        data = torch.stack([token_embeddings.get(token, torch.rand(512)) for token in tokens], dim=0).unsqueeze(0)\n        output = model(data)\n        loss = criterion(output, torch.tensor([label]))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        epoch_acc += calculate_accuracy(output, torch.tensor([label])).item()\n    print(f\"Epoch {epoch}, Loss: {epoch_loss / len(train_sentences)}, Accuracy: {epoch_acc / len(train_sentences)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:50:58.615221Z","iopub.execute_input":"2024-08-06T08:50:58.615674Z","iopub.status.idle":"2024-08-06T08:51:18.673983Z","shell.execute_reply.started":"2024-08-06T08:50:58.615640Z","shell.execute_reply":"2024-08-06T08:51:18.672907Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch 0, Loss: 0.6464293909872451, Accuracy: 0.6097560975609756\nEpoch 1, Loss: 0.6323856858582031, Accuracy: 0.6097560975609756\nEpoch 2, Loss: 0.6254274499852482, Accuracy: 0.6097560975609756\nEpoch 3, Loss: 0.6380398166252346, Accuracy: 0.6097560975609756\nEpoch 4, Loss: 0.6281913168183187, Accuracy: 0.6097560975609756\nEpoch 5, Loss: 0.6316367558589796, Accuracy: 0.6341463414634146\nEpoch 6, Loss: 0.6271933113656393, Accuracy: 0.6097560975609756\nEpoch 7, Loss: 0.6261856995704698, Accuracy: 0.6341463414634146\nEpoch 8, Loss: 0.6340920427223531, Accuracy: 0.6341463414634146\nEpoch 9, Loss: 0.6232872532635201, Accuracy: 0.6097560975609756\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(sentence):\n    model.eval()\n    with torch.no_grad():\n        tokens = sentence.split()\n        # Ensure each token embedding has the correct shape\n        data = torch.stack([token_embeddings.get(token, torch.rand(512)) for token in tokens], dim=0).unsqueeze(0)\n        output = model(data)\n        predicted = torch.argmax(output, dim=1)\n        return \"Positive\" if predicted.item() == 1 else \"Negative\"\n\nsample_sentence = \"This product is  good\"\nprint(f\"'{sample_sentence}' is {predict(sample_sentence)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T08:54:51.331695Z","iopub.execute_input":"2024-08-06T08:54:51.332110Z","iopub.status.idle":"2024-08-06T08:54:51.353167Z","shell.execute_reply.started":"2024-08-06T08:54:51.332078Z","shell.execute_reply":"2024-08-06T08:54:51.351950Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"'This product is  good' is Positive\n","output_type":"stream"}]}]}